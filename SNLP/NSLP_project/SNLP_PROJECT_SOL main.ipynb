{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyttsx3\n",
    "# text = pyttsx3.init()\n",
    "# text.setProperty('rate', 150)\n",
    "# text.setProperty('volume', 1) # 0 to 1\n",
    "# s = '''DOMAIN: Digital content management\n",
    "# • CONTEXT: Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles, etc.\n",
    "# are written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a\n",
    "# classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "# • DATA DESCRIPTION: Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of\n",
    "# 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or\n",
    "# approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and\n",
    "# the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many, industry and/or sign is\n",
    "# marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "# • 8240 \"10s\" blogs (ages 13-17),\n",
    "# • 8086 \"20s\" blogs(ages 23-27) and\n",
    "# • 2994 \"30s\" blogs (ages 33-47)\n",
    "# • For each age group, there is an equal number of male and female bloggers. Each blog in the corpus includes at least 200 occurrences of\n",
    "# common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the\n",
    "# date of the following post and links within a post are denoted by the label url link.\n",
    "# • PROJECT OBJECTIVE: To build a NLP classifier which can use input text parameters to determine the label/s of the blog. Specific to this case\n",
    "# study, you can consider the text of the blog: ‘text’ feature as independent variable and ‘topic’ as dependent variable.\n",
    "# Steps and tasks: [ Total Score: 40 Marks]\n",
    "# 1. Read and Analyse Dataset. [5 Marks]\n",
    "# A. Clearly write outcome of data analysis(Minimum 2 points) [2 Marks]\n",
    "# B. Clean the Structured Data [3 Marks]\n",
    "# i. Missing value analysis and imputation. [1 Marks]\n",
    "# ii. Eliminate Non-English textual data. [2 Marks]\n",
    "# Hint: Refer ‘langdetect’ library to detect language of the input text)\n",
    "# 2. Preprocess unstructured data to make it consumable for model training. [5 Marks]\n",
    "# A. Eliminate All special Characters and Numbers [2 Marks]\n",
    "# B. Lowercase all textual data [1 Marks]\n",
    "# C. Remove all Stopwords [1 Marks]\n",
    "# D. Remove all extra white spaces [1 Marks]\n",
    "# 3. Build a base Classification model [8 Marks]\n",
    "# A. Create dependent and independent variables [2 Marks]\n",
    "# Hint: Treat ‘topic’ as a Target variable.\n",
    "# B. Split data into train and test. [1 Marks]\n",
    "# C. Vectorize data using any one vectorizer. [2 Marks]\n",
    "# D. Build a base model for Supervised Learning - Classification. [2 Marks]\n",
    "# E. Clearly print Performance Metrics. [1 Marks]\n",
    "# Hint: Accuracy, Precision, Recall, ROC-AUC\n",
    "# 4. Improve Performance of model. [14 Marks]\n",
    "# A. Experiment with other vectorisers. [4 Marks]\n",
    "# B. Build classifier Models using other algorithms than base model. [4 Marks]\n",
    "# C. Tune Parameters/Hyperparameters of the model/s. [4 Marks]\n",
    "# D. Clearly print Performance Metrics. [2 Marks]\n",
    "# Hint: Accuracy, Precision, Recall, ROC-AUC\n",
    "\n",
    "# 5. Share insights on relative performance comparison [8 Marks]\n",
    "# A. Which vectorizer performed better? Probable reason?.\n",
    "# [2 Marks]\n",
    "# B. Which model outperformed? Probable reason? [2 Marks]\n",
    "# C. Which parameter/hyperparameter significantly helped\n",
    "# to improve performance?Probable reason?. [2 Marks]\n",
    "# D. According to you, which performance metric should be\n",
    "# given most importance, why?. [2 Marks]'''\n",
    "# text.say(s)\n",
    "# text.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # PART A - 40 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • DOMAIN: \n",
    "        Digital content management\n",
    "### • CONTEXT:\n",
    "        Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles, etc. are written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem. \n",
    "### • DATA DESCRIPTION: \n",
    "        Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many, industry and/or sign is\n",
    "        marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "            • 8240 \"10s\" blogs (ages 13-17),\n",
    "            • 8086 \"20s\" blogs(ages 23-27) and\n",
    "            • 2994 \"30s\" blogs (ages 33-47)\n",
    "            • For each age group, there is an equal number of male and female bloggers. Each blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label url link.\n",
    "### • PROJECT OBJECTIVE: \n",
    "        To build a NLP classifier which can use input text parameters to determine the label/s of the blog. Specific to this case study, you can consider the text of the blog: ‘text’ feature as independent variable and ‘topic’ as dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps and tasks: [ Total Score: 40 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read and Analyse Dataset. [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile('blogs.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('E:\\\\RNN\\\\blogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import contractions_dict\n",
    "import unicodedata\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556470</th>\n",
       "      <td>3071102</td>\n",
       "      <td>female</td>\n",
       "      <td>33</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>27,July,2004</td>\n",
       "      <td>BUT, I KNOW I'M SPECIAL! Seriously,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578653</th>\n",
       "      <td>1578617</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Communications-Media</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>26,July,2004</td>\n",
       "      <td>John C Wright, SF writer and semi-pro w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212727</th>\n",
       "      <td>3157701</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Leo</td>\n",
       "      <td>28,June,2004</td>\n",
       "      <td>Cat had kittens. big whoop. Perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166920</th>\n",
       "      <td>3361994</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>16,May,2004</td>\n",
       "      <td>this should be fun, anybody h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424593</th>\n",
       "      <td>579034</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>29,July,2003</td>\n",
       "      <td>Hey all... every one has these post thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73268</th>\n",
       "      <td>317581</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>20,June,2004</td>\n",
       "      <td>I'm going to pick up Cliff from the air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>883178</td>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>Aries</td>\n",
       "      <td>16,August,2002</td>\n",
       "      <td>Forced into exile by the crap calle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  gender  age                 topic       sign            date  \\\n",
       "556470  3071102  female   33            Technology     Cancer    27,July,2004   \n",
       "578653  1578617    male   27  Communications-Media     Cancer    26,July,2004   \n",
       "212727  3157701    male   15            Non-Profit        Leo    28,June,2004   \n",
       "166920  3361994  female   24            Non-Profit  Capricorn     16,May,2004   \n",
       "424593   579034  female   17               Student   Aquarius    29,July,2003   \n",
       "73268    317581    male   26            Technology    Scorpio    20,June,2004   \n",
       "6358     883178    male   36               Fashion      Aries  16,August,2002   \n",
       "\n",
       "                                                     text  \n",
       "556470             BUT, I KNOW I'M SPECIAL! Seriously,...  \n",
       "578653         John C Wright, SF writer and semi-pro w...  \n",
       "212727               Cat had kittens. big whoop. Perso...  \n",
       "166920                   this should be fun, anybody h...  \n",
       "424593         Hey all... every one has these post thi...  \n",
       "73268          I'm going to pick up Cliff from the air...  \n",
       "6358               Forced into exile by the crap calle...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs  = pd.read_csv('E:\\\\RNN\\\\blogs.zip', compression='zip', header=0, sep=',', quotechar='\"') # reading the content directly from zip file\n",
    "\n",
    "\n",
    "# blogs = pd.read_csv('E:\\\\RNN\\\\blogs\\\\Output_1.csv')\n",
    "blogs.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        A. Clearly write outcome of data analysis(Minimum 2 points) [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.812840e+05</td>\n",
       "      <td>681284</td>\n",
       "      <td>681284.000000</td>\n",
       "      <td>681284</td>\n",
       "      <td>681284</td>\n",
       "      <td>681284</td>\n",
       "      <td>681284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>2616</td>\n",
       "      <td>611652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>02,August,2004</td>\n",
       "      <td>urlLink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>345193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251015</td>\n",
       "      <td>65048</td>\n",
       "      <td>16544</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.397802e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.932326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.247723e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.786009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.114000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.239610e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.607577e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.525660e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.337650e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  gender            age   topic    sign            date  \\\n",
       "count   6.812840e+05  681284  681284.000000  681284  681284          681284   \n",
       "unique           NaN       2            NaN      40      12            2616   \n",
       "top              NaN    male            NaN  indUnk  Cancer  02,August,2004   \n",
       "freq             NaN  345193            NaN  251015   65048           16544   \n",
       "mean    2.397802e+06     NaN      23.932326     NaN     NaN             NaN   \n",
       "std     1.247723e+06     NaN       7.786009     NaN     NaN             NaN   \n",
       "min     5.114000e+03     NaN      13.000000     NaN     NaN             NaN   \n",
       "25%     1.239610e+06     NaN      17.000000     NaN     NaN             NaN   \n",
       "50%     2.607577e+06     NaN      24.000000     NaN     NaN             NaN   \n",
       "75%     3.525660e+06     NaN      26.000000     NaN     NaN             NaN   \n",
       "max     4.337650e+06     NaN      48.000000     NaN     NaN             NaN   \n",
       "\n",
       "                       text  \n",
       "count                681284  \n",
       "unique               611652  \n",
       "top              urlLink     \n",
       "freq                    445  \n",
       "mean                    NaN  \n",
       "std                     NaN  \n",
       "min                     NaN  \n",
       "25%                     NaN  \n",
       "50%                     NaN  \n",
       "75%                     NaN  \n",
       "max                     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "date      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome of Data Analysis\n",
    "\n",
    "* There are 2 genders, 40 topics and 12 signs.\n",
    "* When we look at unique and count for text, we can say there are 69632 (681284 - 611652) duplicate texts. \n",
    "* Among the duplicate blog text, urlLink is repeating mosltly.\n",
    "* We have more male bloggers, most blogs belong to indUnk and most bloggers have cancer as their sign.\n",
    "* There are no null values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B. Clean the Structured Data [3 Marks]\n",
    "                i. Missing value analysis and imputation. [1 Marks]\n",
    "                ii. Eliminate Non-English textual data. [2 Marks]\n",
    "                Hint: Refer ‘langdetect’ library to detect language of the input text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing value \n",
    "blogs.isnull().sum()  # from the count in describe also we can say that there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Blogs before eliminating Non-English Text (681284, 7)\n"
     ]
    }
   ],
   "source": [
    "# Eliminate Non-English textual data using langdetect. \n",
    "print(\"Shape of Blogs before eliminating Non-English Text\", blogs.shape)\n",
    "\n",
    "loc = 0\n",
    "eng = 0\n",
    "other =0\n",
    "for blog in blogs['text']:\n",
    "    \n",
    "    try:\n",
    "        if (detect(blog) == 'en'):\n",
    "            eng = eng + 1\n",
    "        else:\n",
    "            # print(loc)\n",
    "            blogs.drop(loc, inplace = True)\n",
    "            other = other +1\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "    loc = loc +1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Blogs after eleminating Non-English Text: (655041, 3)\n",
      "Number of English Blogs: 651489\n",
      "Number of other language Blogs which were removed: 26243\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Blogs after eleminating Non-English Text:\", blogs.shape)\n",
    "print(\"Number of English Blogs:\", eng)\n",
    "print(\"Number of other language Blogs which were removed:\", other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406605</th>\n",
       "      <td>3630901</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Leo</td>\n",
       "      <td>20,July,2004</td>\n",
       "      <td>S and I were sitting on a park bench ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149310</th>\n",
       "      <td>1405766</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>HumanResources</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>09,Aprill,2004</td>\n",
       "      <td>It's official - I propose a writing con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364881</th>\n",
       "      <td>1912582</td>\n",
       "      <td>female</td>\n",
       "      <td>46</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>23,July,2004</td>\n",
       "      <td>urlLink    QuitNet certificate for 7 days ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275393</th>\n",
       "      <td>3509187</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>06,June,2004</td>\n",
       "      <td>O wait one more thing...  Touching Evil: Aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483578</th>\n",
       "      <td>769349</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>30,May,2004</td>\n",
       "      <td>All right, it's time to get down to som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195444</th>\n",
       "      <td>1951423</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>17,February,2004</td>\n",
       "      <td>I suppose this is about the time where ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  gender  age           topic         sign              date  \\\n",
       "406605  3630901    male   34      Technology          Leo      20,July,2004   \n",
       "149310  1405766    male   24  HumanResources      Scorpio    09,Aprill,2004   \n",
       "364881  1912582  female   46          indUnk        Virgo      23,July,2004   \n",
       "275393  3509187    male   16         Student  Sagittarius      06,June,2004   \n",
       "483578   769349    male   34            Arts      Scorpio       30,May,2004   \n",
       "195444  1951423  female   24            Arts      Scorpio  17,February,2004   \n",
       "\n",
       "                                                     text  \n",
       "406605         S and I were sitting on a park bench ta...  \n",
       "149310         It's official - I propose a writing con...  \n",
       "364881      urlLink    QuitNet certificate for 7 days ...  \n",
       "275393     O wait one more thing...  Touching Evil: Aw...  \n",
       "483578         All right, it's time to get down to som...  \n",
       "195444         I suppose this is about the time where ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(655041, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess unstructured data to make it consumable for model training. [5 Marks]\n",
    "        A. Eliminate All special Characters and Numbers [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def strip_html_tags(text):\n",
    "#     soup = BeautifulSoup(text, \"html.parser\")\n",
    "#     stripped_text = soup.get_text()\n",
    "#     return stripped_text\n",
    "\n",
    "# strip_html_tags('<html><h2>Some important text</h2></html>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider a sentence like (I'll be a Father). If we remove the special characters before contractions, then it becomes 'Ill be a Father'. Which actually changes the entire meaning.\n",
    "# So lets apply contractions first and then remove special characters.\n",
    "\n",
    "def expand_contractions(text,contraction_mapping=contractions_dict):\n",
    "    contractions_pattern=re.compile('({})'.format('|'.join\n",
    "                                      (contraction_mapping.keys())),flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match=contraction.group(0)\n",
    "        first_char=match[0]\n",
    "        expanded_contraction=contraction_mapping.get(match)\\\n",
    "            if contraction_mapping.get(match)\\\n",
    "            else contraction_mapping.get(match.lower())\n",
    "        expanded_contraction=first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction   \n",
    "    \n",
    "    \n",
    "    try:                   \n",
    "        expanded_text=contractions_pattern.sub(expand_match,str(text))\n",
    "        expanded_text=re.sub(\"'\",\" \",expanded_text)\n",
    "    except:\n",
    "        return text\n",
    "    return expanded_text\n",
    "\n",
    "def remove_spl_char_n_numbers(text, remove_digits=True):\n",
    "    # text = expand_contractions(text)\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681279</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  I could write some really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681280</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  'I have the second yeast i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681281</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  Your 'boyfriend' is fuckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681282</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan:    Just to clarify, I am as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681283</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Hey everybody...and Susan,  You might a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id gender  age    topic    sign          date  \\\n",
       "681279  1713845   male   23  Student  Taurus  01,July,2004   \n",
       "681280  1713845   male   23  Student  Taurus  01,July,2004   \n",
       "681281  1713845   male   23  Student  Taurus  01,July,2004   \n",
       "681282  1713845   male   23  Student  Taurus  01,July,2004   \n",
       "681283  1713845   male   23  Student  Taurus  01,July,2004   \n",
       "\n",
       "                                                     text  \n",
       "681279         Dear Susan,  I could write some really ...  \n",
       "681280         Dear Susan,  'I have the second yeast i...  \n",
       "681281         Dear Susan,  Your 'boyfriend' is fuckin...  \n",
       "681282         Dear Susan:    Just to clarify, I am as...  \n",
       "681283         Hey everybody...and Susan,  You might a...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>2581876</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>13,June,2004</td>\n",
       "      <td>filomena is the girl i want to be with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464081</th>\n",
       "      <td>2938013</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>28,July,2004</td>\n",
       "      <td>It is officialnbsp Jazz is my all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138194</th>\n",
       "      <td>1935335</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>Banking</td>\n",
       "      <td>Aries</td>\n",
       "      <td>27,June,2004</td>\n",
       "      <td>Each week millions of Americans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355533</th>\n",
       "      <td>49663</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>27,September,2000</td>\n",
       "      <td>Absolutely Fabulous fans click  url...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358325</th>\n",
       "      <td>1280497</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>05,November,2003</td>\n",
       "      <td>I have to post a eulogy of so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88268</th>\n",
       "      <td>320317</td>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>01,April,2002</td>\n",
       "      <td>urlLink IBM Ease of Use What is us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288926</th>\n",
       "      <td>3401120</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>06,June,2004</td>\n",
       "      <td>one of my older cousins Frank or Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635967</th>\n",
       "      <td>3306589</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Science</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Great game  urlLink check out the dehem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654390</th>\n",
       "      <td>4087530</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>02,August,2004</td>\n",
       "      <td>Momentarily listening to Lali Puna Faki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222880</th>\n",
       "      <td>1477098</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>22,April,2004</td>\n",
       "      <td>I went to Penn Station to get an ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144807</th>\n",
       "      <td>2627816</td>\n",
       "      <td>male</td>\n",
       "      <td>13</td>\n",
       "      <td>Education</td>\n",
       "      <td>Libra</td>\n",
       "      <td>11,May,2004</td>\n",
       "      <td>I am UPDATING I am going to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74075</th>\n",
       "      <td>2040365</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>09,October,2003</td>\n",
       "      <td>wow  chk this out  do you know ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536230</th>\n",
       "      <td>1391636</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>Religion</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>05,September,2002</td>\n",
       "      <td>I went for a walk today  It rained  pou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295985</th>\n",
       "      <td>3053026</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>02,June,2004</td>\n",
       "      <td>Thank you Mary for providing some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606762</th>\n",
       "      <td>1131517</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>22,April,2003</td>\n",
       "      <td>Today was a real drag I dont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476690</th>\n",
       "      <td>3647663</td>\n",
       "      <td>female</td>\n",
       "      <td>45</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>15,June,2004</td>\n",
       "      <td>Today I worked at Weber Aircraft from  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73465</th>\n",
       "      <td>2936892</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>22,May,2004</td>\n",
       "      <td>Hi back in here but in a terrible m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403268</th>\n",
       "      <td>3952637</td>\n",
       "      <td>female</td>\n",
       "      <td>33</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>20,July,2004</td>\n",
       "      <td>urlLink    Who am I  Once upon a time ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  gender  age          topic         sign               date  \\\n",
       "9141    2581876  female   24         indUnk  Sagittarius       13,June,2004   \n",
       "464081  2938013    male   23    Engineering    Capricorn       28,July,2004   \n",
       "138194  1935335  female   25        Banking        Aries       27,June,2004   \n",
       "355533    49663    male   33         indUnk       Taurus  27,September,2000   \n",
       "358325  1280497    male   26     Technology       Taurus   05,November,2003   \n",
       "88268    320317    male   36     Technology       Pisces      01,April,2002   \n",
       "288926  3401120    male   15        Student       Cancer       06,June,2004   \n",
       "635967  3306589    male   27        Science       Taurus       11,June,2004   \n",
       "654390  4087530  female   16        Student       Taurus     02,August,2004   \n",
       "222880  1477098  female   17      Marketing  Sagittarius      22,April,2004   \n",
       "144807  2627816    male   13      Education        Libra        11,May,2004   \n",
       "74075   2040365    male   26    Engineering    Capricorn    09,October,2003   \n",
       "536230  1391636  female   26       Religion       Cancer  05,September,2002   \n",
       "295985  3053026    male   17         indUnk     Aquarius       02,June,2004   \n",
       "606762  1131517  female   17         indUnk       Gemini      22,April,2003   \n",
       "476690  3647663  female   45  Manufacturing  Sagittarius       15,June,2004   \n",
       "73465   2936892  female   14        Student       Cancer        22,May,2004   \n",
       "403268  3952637  female   33     Non-Profit     Aquarius       20,July,2004   \n",
       "\n",
       "                                                     text  \n",
       "9141           filomena is the girl i want to be with ...  \n",
       "464081               It is officialnbsp Jazz is my all...  \n",
       "138194               Each week millions of Americans t...  \n",
       "355533             Absolutely Fabulous fans click  url...  \n",
       "358325                   I have to post a eulogy of so...  \n",
       "88268               urlLink IBM Ease of Use What is us...  \n",
       "288926             one of my older cousins Frank or Fr...  \n",
       "635967         Great game  urlLink check out the dehem...  \n",
       "654390         Momentarily listening to Lali Puna Faki...  \n",
       "222880             I went to Penn Station to get an ap...  \n",
       "144807                   I am UPDATING I am going to t...  \n",
       "74075              wow  chk this out  do you know ther...  \n",
       "536230         I went for a walk today  It rained  pou...  \n",
       "295985               Thank you Mary for providing some...  \n",
       "606762                   Today was a real drag I dont ...  \n",
       "476690         Today I worked at Weber Aircraft from  ...  \n",
       "73465              Hi back in here but in a terrible m...  \n",
       "403268          urlLink    Who am I  Once upon a time ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i = 0\n",
    "# for blog in blogs['text']:\n",
    "#     blog = remove_spl_char_n_numbers(blog)\n",
    "    \n",
    "\n",
    "blogs['text'] = blogs['text'].apply(expand_contractions)\n",
    "blogs['text'] = blogs['text'].apply(remove_spl_char_n_numbers)\n",
    "blogs.sample(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blogs.drop(columns=[\"gender\", 'age','sign','date','text_new'],inplace=True)\n",
    "# blogs.drop(columns=['text_new2'],inplace=True)\n",
    "# blogs.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i'll probably be moving to canada  \""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(\"i'll probably be moving to canada  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import unicodedata\n",
    "# def remove_accented_chars(text):\n",
    "#     text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "#     return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def simple_stemmer(text):\n",
    "#     ps = nltk.porter.PorterStemmer()\n",
    "#     text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "#     return text\n",
    "\n",
    "# simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")\n",
    "\n",
    "\n",
    "\n",
    "# def lemmatize_text(text):\n",
    "#     text = nlp(text)\n",
    "#     text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "#     return text\n",
    "\n",
    "# lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")\n",
    "\n",
    "\n",
    "# def remove_stopwords(text, is_lower_case=False):\n",
    "#     tokens = tokenizer.tokenize(text)\n",
    "#     tokens = [token.strip() for token in tokens]\n",
    "#     if is_lower_case:\n",
    "#         filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "#     else:\n",
    "#         filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "#     filtered_text = ' '.join(filtered_tokens)    \n",
    "#     return filtered_text\n",
    "\n",
    "# remove_stopwords(\"The, and, if are stopwords, computer is not\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B. Lowercase all textual data [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451930</th>\n",
       "      <td>2983546</td>\n",
       "      <td>female</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>03,August,2004</td>\n",
       "      <td>fine i admit it i am envious i envy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540086</th>\n",
       "      <td>2020321</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>07,May,2004</td>\n",
       "      <td>chris  i saw van helsing after dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282024</th>\n",
       "      <td>958176</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>08,October,2003</td>\n",
       "      <td>that is very true  using my m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616958</th>\n",
       "      <td>3365547</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>17,May,2004</td>\n",
       "      <td>deviant   urllink ssilence   my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  gender  age       topic         sign             date  \\\n",
       "451930  2983546  female   33      indUnk        Aries   03,August,2004   \n",
       "540086  2020321  female   25      indUnk  Sagittarius      07,May,2004   \n",
       "282024   958176    male   17  Non-Profit       Gemini  08,October,2003   \n",
       "616958  3365547    male   17      indUnk      Scorpio      17,May,2004   \n",
       "\n",
       "                                                     text  \n",
       "451930             fine i admit it i am envious i envy...  \n",
       "540086               chris  i saw van helsing after dr...  \n",
       "282024                   that is very true  using my m...  \n",
       "616958                deviant   urllink ssilence   my ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs['text'] = blogs['text'].apply(lambda x:x.lower())\n",
    "blogs.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        C. Remove all Stopwords [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144869</th>\n",
       "      <td>3820472</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Aries</td>\n",
       "      <td>17,July,2004</td>\n",
       "      <td>okie time special abit st thing coz early sund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26178</th>\n",
       "      <td>1939766</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>08,July,2004</td>\n",
       "      <td>tomorrow big day quitting maybe quitting song ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362100</th>\n",
       "      <td>3585348</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,August,2004</td>\n",
       "      <td>would got ehemail banksy sent one followed think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185008</th>\n",
       "      <td>3971148</td>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Leo</td>\n",
       "      <td>23,July,2004</td>\n",
       "      <td>getting phone calls someone whose name recall ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  gender  age      topic      sign            date  \\\n",
       "144869  3820472  female   17    Student     Aries    17,July,2004   \n",
       "26178   1939766  female   23       Arts  Aquarius    08,July,2004   \n",
       "362100  3585348    male   25  Chemicals  Aquarius  09,August,2004   \n",
       "185008  3971148  female   27       Arts       Leo    23,July,2004   \n",
       "\n",
       "                                                     text  \n",
       "144869  okie time special abit st thing coz early sund...  \n",
       "26178   tomorrow big day quitting maybe quitting song ...  \n",
       "362100   would got ehemail banksy sent one followed think  \n",
       "185008  getting phone calls someone whose name recall ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "blogs['text'] = blogs['text'].apply(remove_stopwords)\n",
    "blogs.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "        D. Remove all extra white spaces [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115637</th>\n",
       "      <td>3403444</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>11,July,2004</td>\n",
       "      <td>fabityfabfab davida listen mesing fabityfabfab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438765</th>\n",
       "      <td>2159339</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>days nbsp days loafing around im taking rest w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642856</th>\n",
       "      <td>2608756</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>Education</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>22,March,2004</td>\n",
       "      <td>ive working another column bilingual newspaper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520742</th>\n",
       "      <td>898887</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>31,May,2003</td>\n",
       "      <td>shit didnt hit fan everything else know usuall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618672</th>\n",
       "      <td>1684840</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>06,August,2003</td>\n",
       "      <td>woohoo got back city sweating like pig got loa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11712</th>\n",
       "      <td>3668449</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Banking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>29,June,2004</td>\n",
       "      <td>urllink dnbsp urllink summarization english la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208382</th>\n",
       "      <td>2681786</td>\n",
       "      <td>female</td>\n",
       "      <td>36</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>07,August,2004</td>\n",
       "      <td>urllink summer smith courtesy urllink bunny eh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247729</th>\n",
       "      <td>4075390</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>27,October,2003</td>\n",
       "      <td>whilst driving work today flipping morning rad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368785</th>\n",
       "      <td>3579464</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>09,July,2004</td>\n",
       "      <td>official worlds biggest flirt worked hour shif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85645</th>\n",
       "      <td>2259044</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>22,December,2003</td>\n",
       "      <td>jello ive come strange conclusion jello u may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  gender  age       topic      sign              date  \\\n",
       "115637  3403444  female   14      indUnk    Taurus      11,July,2004   \n",
       "438765  2159339  female   26  Technology     Aries      03,July,2004   \n",
       "642856  2608756  female   38   Education    Gemini     22,March,2004   \n",
       "520742   898887    male   24      indUnk    Gemini       31,May,2003   \n",
       "618672  1684840    male   15     Student   Scorpio    06,August,2003   \n",
       "11712   3668449  female   24     Banking  Aquarius      29,June,2004   \n",
       "208382  2681786  female   36     Fashion    Pisces    07,August,2004   \n",
       "247729  4075390  female   24  Non-Profit    Pisces   27,October,2003   \n",
       "368785  3579464  female   16     Student       Leo      09,July,2004   \n",
       "85645   2259044  female   16     Student       Leo  22,December,2003   \n",
       "\n",
       "                                                     text  \n",
       "115637  fabityfabfab davida listen mesing fabityfabfab...  \n",
       "438765  days nbsp days loafing around im taking rest w...  \n",
       "642856  ive working another column bilingual newspaper...  \n",
       "520742  shit didnt hit fan everything else know usuall...  \n",
       "618672  woohoo got back city sweating like pig got loa...  \n",
       "11712   urllink dnbsp urllink summarization english la...  \n",
       "208382  urllink summer smith courtesy urllink bunny eh...  \n",
       "247729  whilst driving work today flipping morning rad...  \n",
       "368785  official worlds biggest flirt worked hour shif...  \n",
       "85645   jello ive come strange conclusion jello u may ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_whitespaces(text):\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "blogs['text'] = blogs['text'].apply(remove_whitespaces)\n",
    "blogs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blogs['text_new3'].str.replace(\"  \",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a base Classification model [8 Marks]\n",
    "        A. Create dependent and independent variables [2 Marks]\n",
    "        Hint: Treat ‘topic’ as a Target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since X = blogs['text'] and y =['topic']]\n",
    "\n",
    "x = blogs['text']\n",
    "\n",
    "y = blogs['topic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B. Split data into train and test. [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test =train_test_split(x,y, random_state=369)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        C. Vectorize data using any one vectorizer. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (655041,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102704"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=10) # lowercase=True,stop_words='english' are handled already\n",
    "print('x shape:',x_train.shape)\n",
    "cv.fit_transform(x_train)\n",
    "\n",
    "#Check the vocablury size\n",
    "len(cv.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491280, 102704)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert Training blog text into Count Vectors\n",
    "x_train_ct = cv.transform(x_train)\n",
    "\n",
    "#Size of Document Term Matrix\n",
    "x_train_ct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163761, 102704)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply transform on test data\n",
    "x_test_ct = cv.transform(x_test)\n",
    "x_test_ct.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        D. Build a base model for Supervised Learning - Classification. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features :  102704\n",
      "Training Accuracy :  0.4187103077674646\n",
      "Testing Accuracy :  0.35957889851674085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_ct, y_train)\n",
    "y_pred_class = nb.predict(x_test_ct)\n",
    "print(\"Number of Features : \", x_train_ct.shape[1])\n",
    "print(\"Training Accuracy : \",nb.score(x_train_ct,y_train ))\n",
    "print(\"Testing Accuracy : \", nb.score(x_test_ct,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        E. Clearly print Performance Metrics. [1 Marks]\n",
    "        Hint: Accuracy, Precision, Recall, ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             Accounting       0.41      0.21      0.28       897\n",
      "            Advertising       0.27      0.04      0.07      1115\n",
      "            Agriculture       0.22      0.01      0.01       287\n",
      "           Architecture       0.16      0.11      0.13       387\n",
      "                   Arts       0.21      0.22      0.22      7726\n",
      "             Automotive       0.00      0.00      0.00       273\n",
      "                Banking       0.19      0.04      0.07       973\n",
      "                Biotech       0.30      0.05      0.09       552\n",
      "       BusinessServices       0.50      0.13      0.21      1073\n",
      "              Chemicals       0.14      0.04      0.07       914\n",
      "   Communications-Media       0.16      0.15      0.15      4915\n",
      "           Construction       0.06      0.01      0.01       249\n",
      "             Consulting       0.17      0.04      0.07      1423\n",
      "              Education       0.25      0.15      0.19      7206\n",
      "            Engineering       0.31      0.13      0.18      2849\n",
      "            Environment       0.07      0.01      0.01       156\n",
      "                Fashion       0.59      0.22      0.32      1193\n",
      "             Government       0.28      0.08      0.12      1612\n",
      "         HumanResources       0.17      0.02      0.04       735\n",
      "               Internet       0.17      0.15      0.16      3907\n",
      "      InvestmentBanking       0.00      0.00      0.00       293\n",
      "                    Law       0.12      0.24      0.16      2247\n",
      "LawEnforcement-Security       0.33      0.01      0.02       468\n",
      "          Manufacturing       0.30      0.02      0.03       552\n",
      "               Maritime       0.00      0.00      0.00        66\n",
      "              Marketing       0.22      0.05      0.08      1130\n",
      "               Military       0.22      0.06      0.09       740\n",
      "      Museums-Libraries       0.42      0.09      0.14       783\n",
      "             Non-Profit       0.23      0.09      0.13      3562\n",
      "             Publishing       0.14      0.31      0.19      1884\n",
      "             RealEstate       0.18      0.04      0.07       709\n",
      "               Religion       0.11      0.26      0.16      1222\n",
      "                Science       0.16      0.09      0.12      1730\n",
      "      Sports-Recreation       0.16      0.05      0.08       755\n",
      "                Student       0.43      0.55      0.48     36817\n",
      "             Technology       0.24      0.31      0.27     10005\n",
      "     Telecommunications       0.15      0.03      0.05       910\n",
      "                Tourism       0.44      0.05      0.09       467\n",
      "         Transportation       0.85      0.19      0.31       569\n",
      "                 indUnk       0.44      0.46      0.45     60410\n",
      "\n",
      "               accuracy                           0.36    163761\n",
      "              macro avg       0.24      0.12      0.13    163761\n",
      "           weighted avg       0.35      0.36      0.34    163761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the confusion matrix\n",
    "# print(confusion_matrix(y_test, y_pred_class))\n",
    "# Printing the precision and recall, among other metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Improve Performance of model. [14 Marks]\n",
    "        A. Experiment with other vectorisers. [4 Marks]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87083"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets use Tfidf Vectorizer now\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(min_df=10)\n",
    "tv.fit_transform(x_train)\n",
    "#Check the vocablury size\n",
    "len(tv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491280, 87083)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert Training blog text into Count Vectors\n",
    "x_train_tv = tv.transform(x_train)\n",
    "\n",
    "#Size of Document Term Matrix\n",
    "x_train_tv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163761, 87083)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply transform on test data\n",
    "x_test_tv = tv.transform(x_test)\n",
    "x_test_tv.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B. Build classifier Models using other algorithms than base model. [4 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(max_depth=100)\n",
    "rfclf.fit(x_train_tv, y_train)\n",
    "y_pred_class = nb.predict(x_test_ct)\n",
    "print(\"Number of Features : \", x_train_tv.shape[1])\n",
    "print(\"Training Accuracy : \",rfclf.score(x_train_tv,y_train ))\n",
    "print(\"Testing Accuracy : \", rfclf.score(x_test_tv,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        C. Tune Parameters/Hyperparameters of the model/s. [4 Marks]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf2 = RandomForestClassifier(max_depth=200)\n",
    "rfclf2.fit(x_train_tv, y_train)\n",
    "y_pred_class = nb.predict(x_test_ct)\n",
    "print(\"Number of Features : \", x_train_tv.shape[1])\n",
    "print(\"Training Accuracy : \",rfclf2.score(x_train_tv,y_train ))\n",
    "print(\"Testing Accuracy : \", rfclf2.score(x_test_tv,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        D. Clearly print Performance Metrics. [2 Marks]\n",
    "            Hint: Accuracy, Precision, Recall, ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Share insights on relative performance comparison [8 Marks]\n",
    "        A. Which vectorizer performed better? Probable reason?.[2 Marks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B. Which model outperformed? Probable reason? [2 Marks]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        C. Which parameter/hyperparameter significantly helped to improve performance?Probable reason?. [2 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        D. According to you, which performance metric should be given most importance, why?. [2 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # PART B - 20 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • DOMAIN: \n",
    "    Customer support\n",
    "### • CONTEXT: \n",
    "    Great Learning has a an academic support department which receives numerous support requests every day throughout the year. Teams are spread across geographies and try to provide support round the year. Sometimes there are circumstances where due to heavy workload certain request resolutions are delayed, impacting company’s business. Some of the requests are very generic where a proper resolution procedure delivered to the user can solve the problem. Company is looking forward to design an automation which can interact with the user, understand the problem and display the resolution procedure [ if found as a generic request ] or redirect the request to an actual human support executive if the request is complex or not in it’s database.\n",
    "### • DATA DESCRIPTION: \n",
    "    A sample corpus is attached for your reference. Please enhance/add more data to the corpus using your linguistics skills.\n",
    "### • PROJECT OBJECTIVE: \n",
    "    Design a python based interactive semi - rule based chatbot which can do the following:\n",
    "        1. Start chat session with greetings and ask what the user is looking for. [5 Marks]\n",
    "        2. Accept dynamic text based questions from the user. Reply back with relevant answer from the designed corpus. [10 Marks]\n",
    "        3. End the chat session only if the user requests to end else ask what the user is looking for. Loop continues till the user asks to end it. [5 Marks]\n",
    "        Hint: There are a lot of techniques using which one can clean and prepare the data which can be used to train a ML/DL classifier. Hence, it might require you to experiment, research, self learn and implement the above classifier. There might be many iterations between hand building the corpus and designing the best fit text classifier. As the quality and quantity of corpus increases the model’s performance i.e. ability to answer\n",
    "        right questions also increases.\n",
    "        Reference: https://www.mygreatlearning.com/blog/basics-of-building-an-artificial-intelligence-chatbot/\n",
    "### • Evaluation: \n",
    "    Evaluator will use linguistics to twist and turn sentences to ask questions on the topics described in DATA DESCRIPTION and check if the bot is giving relevant replies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texttospeech' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18104/113463108.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtexttospeech\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'texttospeech' is not defined"
     ]
    }
   ],
   "source": [
    "texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "text = pyttsx3.init()\n",
    "s = 'The code is Compiled'\n",
    "text.say(s)\n",
    "text.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
