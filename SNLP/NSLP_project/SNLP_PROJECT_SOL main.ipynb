{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyttsx3\n",
    "# text = pyttsx3.init()\n",
    "# text.setProperty('rate', 150)\n",
    "# text.setProperty('volume', 1) # 0 to 1\n",
    "# s = '''DOMAIN: Digital content management\n",
    "# • CONTEXT: Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles, etc.\n",
    "# are written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a\n",
    "# classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "# • DATA DESCRIPTION: Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of\n",
    "# 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or\n",
    "# approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and\n",
    "# the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many, industry and/or sign is\n",
    "# marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "# • 8240 \"10s\" blogs (ages 13-17),\n",
    "# • 8086 \"20s\" blogs(ages 23-27) and\n",
    "# • 2994 \"30s\" blogs (ages 33-47)\n",
    "# • For each age group, there is an equal number of male and female bloggers. Each blog in the corpus includes at least 200 occurrences of\n",
    "# common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the\n",
    "# date of the following post and links within a post are denoted by the label url link.\n",
    "# • PROJECT OBJECTIVE: To build a NLP classifier which can use input text parameters to determine the label/s of the blog. Specific to this case\n",
    "# study, you can consider the text of the blog: ‘text’ feature as independent variable and ‘topic’ as dependent variable.\n",
    "# Steps and tasks: [ Total Score: 40 Marks]\n",
    "# 1. Read and Analyse Dataset. [5 Marks]\n",
    "# A. Clearly write outcome of data analysis(Minimum 2 points) [2 Marks]\n",
    "# B. Clean the Structured Data [3 Marks]\n",
    "# i. Missing value analysis and imputation. [1 Marks]\n",
    "# ii. Eliminate Non-English textual data. [2 Marks]\n",
    "# Hint: Refer ‘langdetect’ library to detect language of the input text)\n",
    "# 2. Preprocess unstructured data to make it consumable for model training. [5 Marks]\n",
    "# A. Eliminate All special Characters and Numbers [2 Marks]\n",
    "# B. Lowercase all textual data [1 Marks]\n",
    "# C. Remove all Stopwords [1 Marks]\n",
    "# D. Remove all extra white spaces [1 Marks]\n",
    "# 3. Build a base Classification model [8 Marks]\n",
    "# A. Create dependent and independent variables [2 Marks]\n",
    "# Hint: Treat ‘topic’ as a Target variable.\n",
    "# B. Split data into train and test. [1 Marks]\n",
    "# C. Vectorize data using any one vectorizer. [2 Marks]\n",
    "# D. Build a base model for Supervised Learning - Classification. [2 Marks]\n",
    "# E. Clearly print Performance Metrics. [1 Marks]\n",
    "# Hint: Accuracy, Precision, Recall, ROC-AUC\n",
    "# 4. Improve Performance of model. [14 Marks]\n",
    "# A. Experiment with other vectorisers. [4 Marks]\n",
    "# B. Build classifier Models using other algorithms than base model. [4 Marks]\n",
    "# C. Tune Parameters/Hyperparameters of the model/s. [4 Marks]\n",
    "# D. Clearly print Performance Metrics. [2 Marks]\n",
    "# Hint: Accuracy, Precision, Recall, ROC-AUC\n",
    "\n",
    "# 5. Share insights on relative performance comparison [8 Marks]\n",
    "# A. Which vectorizer performed better? Probable reason?.\n",
    "# [2 Marks]\n",
    "# B. Which model outperformed? Probable reason? [2 Marks]\n",
    "# C. Which parameter/hyperparameter significantly helped\n",
    "# to improve performance?Probable reason?. [2 Marks]\n",
    "# D. According to you, which performance metric should be\n",
    "# given most importance, why?. [2 Marks]'''\n",
    "# text.say(s)\n",
    "# text.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # PART A - 40 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • DOMAIN: \n",
    "        Digital content management\n",
    "### • CONTEXT:\n",
    "        Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles, etc. are written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem. \n",
    "### • DATA DESCRIPTION: \n",
    "        Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many, industry and/or sign is\n",
    "        marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "            • 8240 \"10s\" blogs (ages 13-17),\n",
    "            • 8086 \"20s\" blogs(ages 23-27) and\n",
    "            • 2994 \"30s\" blogs (ages 33-47)\n",
    "            • For each age group, there is an equal number of male and female bloggers. Each blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label url link.\n",
    "### • PROJECT OBJECTIVE: \n",
    "        To build a NLP classifier which can use input text parameters to determine the label/s of the blog. Specific to this case study, you can consider the text of the blog: ‘text’ feature as independent variable and ‘topic’ as dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps and tasks: [ Total Score: 40 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read and Analyse Dataset. [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile('blogs.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('E:\\\\RNN\\\\blogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import contractions_dict\n",
    "import unicodedata\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>not yet, but I did almost buy a Buf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>1238294</td>\n",
       "      <td>female</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,July,2004</td>\n",
       "      <td>Look at this yummy yarn:   It cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>649790</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>11,January,2003</td>\n",
       "      <td>Ah hah!  So that's what  urlLink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>renee zellwegger looks like a shave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>3176655</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Libra</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>Forgive me friends for I have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>I was with you until the last sente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>649790</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>27,July,2002</td>\n",
       "      <td>Quizzes   Here are a couple I t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  gender  age        topic     sign             date  \\\n",
       "1623   589736    male   35   Technology    Aries   05,August,2004   \n",
       "1177  1238294  female   33       indUnk      Leo     13,July,2004   \n",
       "390    649790  female   24       indUnk  Scorpio  11,January,2003   \n",
       "3532   589736    male   35   Technology    Aries   05,August,2004   \n",
       "587   3176655    male   24  Engineering    Libra     03,July,2004   \n",
       "2647   589736    male   35   Technology    Aries   05,August,2004   \n",
       "307    649790  female   24       indUnk  Scorpio     27,July,2002   \n",
       "\n",
       "                                                   text  \n",
       "1623             not yet, but I did almost buy a Buf...  \n",
       "1177               Look at this yummy yarn:   It cam...  \n",
       "390                 Ah hah!  So that's what  urlLink...  \n",
       "3532             renee zellwegger looks like a shave...  \n",
       "587                    Forgive me friends for I have...  \n",
       "2647             I was with you until the last sente...  \n",
       "307                  Quizzes   Here are a couple I t...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blogs  = pd.read_csv('E:\\\\RNN\\\\blogs.zip', compression='zip', header=0, sep=',', quotechar='\"') # reading the content directly from zip file\n",
    "\n",
    "\n",
    "blogs = pd.read_csv('E:\\\\RNN\\\\blogs\\\\Output_1.csv')\n",
    "blogs.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        A. Clearly write outcome of data analysis(Minimum 2 points) [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>573</td>\n",
       "      <td>4978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>urlLink    urlLink audblog audio post ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2332</td>\n",
       "      <td>2483</td>\n",
       "      <td>2311</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.532153e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.544600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.302576e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.766008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.677050e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.897360e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.497900e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.168577e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.321554e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id gender          age       topic   sign            date  \\\n",
       "count   5.000000e+03   5000  5000.000000        5000   5000            5000   \n",
       "unique           NaN      2          NaN          20     12             573   \n",
       "top              NaN   male          NaN  Technology  Aries  05,August,2004   \n",
       "freq             NaN   3294          NaN        2332   2483            2311   \n",
       "mean    1.532153e+06    NaN    29.544600         NaN    NaN             NaN   \n",
       "std     1.302576e+06    NaN     7.766008         NaN    NaN             NaN   \n",
       "min     4.677050e+05    NaN    14.000000         NaN    NaN             NaN   \n",
       "25%     5.897360e+05    NaN    24.000000         NaN    NaN             NaN   \n",
       "50%     6.497900e+05    NaN    35.000000         NaN    NaN             NaN   \n",
       "75%     3.168577e+06    NaN    35.000000         NaN    NaN             NaN   \n",
       "max     4.321554e+06    NaN    46.000000         NaN    NaN             NaN   \n",
       "\n",
       "                                                     text  \n",
       "count                                                5000  \n",
       "unique                                               4978  \n",
       "top             urlLink    urlLink audblog audio post ...  \n",
       "freq                                                    7  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "date      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome of Data Analysis\n",
    "\n",
    "* There are 2 genders, 40 topics and 12 signs.\n",
    "* When we look at unique and count for text, we can say there are 69632 (681284 - 611652) duplicate texts. \n",
    "* Among the duplicate blog text, urlLink is repeating mosltly.\n",
    "* We have more male bloggers, most blogs belong to indUnk and most bloggers have cancer as their sign.\n",
    "* There are no null values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B. Clean the Structured Data [3 Marks]\n",
    "                i. Missing value analysis and imputation. [1 Marks]\n",
    "                ii. Eliminate Non-English textual data. [2 Marks]\n",
    "                Hint: Refer ‘langdetect’ library to detect language of the input text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing value \n",
    "blogs.isnull().sum()  # from the count in describe also we can say that there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Blogs before eliminating Non-English Text (5000, 7)\n"
     ]
    }
   ],
   "source": [
    "# Eliminate Non-English textual data using langdetect. \n",
    "print(\"Shape of Blogs before eliminating Non-English Text\", blogs.shape)\n",
    "\n",
    "loc = 0\n",
    "eng = 0\n",
    "other =0\n",
    "for blog in blogs['text']:\n",
    "    \n",
    "    try:\n",
    "        if (detect(blog) == 'en'):\n",
    "            eng = eng + 1\n",
    "        else:\n",
    "            # print(loc)\n",
    "            blogs.drop(loc, inplace = True)\n",
    "            other = other +1\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "    loc = loc +1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Blogs after eleminating Non-English Text: (4734, 7)\n",
      "Number of English Blogs: 4722\n",
      "Number of other language Blogs which were removed: 266\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Blogs after eleminating Non-English Text:\", blogs.shape)\n",
    "print(\"Number of English Blogs:\", eng)\n",
    "print(\"Number of other language Blogs which were removed:\", other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess unstructured data to make it consumable for model training. [5 Marks]\n",
    "        A. Eliminate All special Characters and Numbers [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider a sentence like (I'll be a Father). If we remove the special characters before contractions, then it becomes 'Ill be a Father'. Which actually changes the entire meaning.\n",
    "# So lets apply contractions first and then remove special characters.\n",
    "\n",
    "def expand_contractions(text,contraction_mapping=contractions_dict):\n",
    "    contractions_pattern=re.compile('({})'.format('|'.join\n",
    "                                      (contraction_mapping.keys())),flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match=contraction.group(0)\n",
    "        first_char=match[0]\n",
    "        expanded_contraction=contraction_mapping.get(match)\\\n",
    "            if contraction_mapping.get(match)\\\n",
    "            else contraction_mapping.get(match.lower())\n",
    "        expanded_contraction=first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction   \n",
    "    \n",
    "    \n",
    "    try:                   \n",
    "        expanded_text=contractions_pattern.sub(expand_match,str(text))\n",
    "        expanded_text=re.sub(\"'\",\" \",expanded_text)\n",
    "    except:\n",
    "        return text\n",
    "    return expanded_text\n",
    "\n",
    "def remove_spl_char_n_numbers(text, remove_digits=True):\n",
    "    # text = expand_contractions(text)\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'she will be probably moving to India'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(\"she'll be probably moving to India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1103575</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>27,August,2003</td>\n",
       "      <td>So... I had another one of those dreams...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1103575</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>27,August,2003</td>\n",
       "      <td>mmm... strawberry tea for breakfast. To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1103575</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>27,August,2003</td>\n",
       "      <td>Yay for a new layout!!  Yeah, I know, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1103575</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>26,August,2003</td>\n",
       "      <td>Ok, so I lied... Fed up isn't playing F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1103575</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>26,August,2003</td>\n",
       "      <td>well, today I went to church and talked...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  gender  age   topic     sign            date  \\\n",
       "4995  1103575  female   17  indUnk  Scorpio  27,August,2003   \n",
       "4996  1103575  female   17  indUnk  Scorpio  27,August,2003   \n",
       "4997  1103575  female   17  indUnk  Scorpio  27,August,2003   \n",
       "4998  1103575  female   17  indUnk  Scorpio  26,August,2003   \n",
       "4999  1103575  female   17  indUnk  Scorpio  26,August,2003   \n",
       "\n",
       "                                                   text  \n",
       "4995         So... I had another one of those dreams...  \n",
       "4996         mmm... strawberry tea for breakfast. To...  \n",
       "4997         Yay for a new layout!!  Yeah, I know, I...  \n",
       "4998         Ok, so I lied... Fed up isn't playing F...  \n",
       "4999         well, today I went to church and talked...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>Okay  a  how does one stumble upon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>Here in this place I have no sound ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>did anyone besides me see our frien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>yep and i have a copy on the way   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>4013263</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>23,July,2004</td>\n",
       "      <td>My new job is greatnbsp I sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>766556</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>06,January,2003</td>\n",
       "      <td>Another  Borrowed  Toy  My  Cyborg  na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>766556</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>22,November,2002</td>\n",
       "      <td>Oh What a night  Late September back i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1238294</td>\n",
       "      <td>female</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>21,July,2004</td>\n",
       "      <td>I finished another  urlLink tiny ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>766556</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>01,October,2003</td>\n",
       "      <td>Oh and one more thing   October is her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>766556</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>16,September,2002</td>\n",
       "      <td>Cleaning House   First of all thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>RTG  check your ehemail Sunday morn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>right now i have on no shoes  no sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>3176655</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Libra</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>Happy friday    I am happy an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>3887270</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>21,July,2004</td>\n",
       "      <td>oh YEAH and im the FIRST PERSON O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>3887270</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>22,July,2004</td>\n",
       "      <td>Some people live for the fortune  S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>1103575</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>28,July,2003</td>\n",
       "      <td>Sometimes    I think my name is Jane   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>3808902</td>\n",
       "      <td>female</td>\n",
       "      <td>45</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>02,July,2004</td>\n",
       "      <td>Well Independance Day is upon us and I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>Waiting for the Feeling Police   Al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  gender  age        topic         sign               date  \\\n",
       "1602   589736    male   35   Technology        Aries     05,August,2004   \n",
       "2771   589736    male   35   Technology        Aries     05,August,2004   \n",
       "2358   589736    male   35   Technology        Aries     05,August,2004   \n",
       "2947   589736    male   35   Technology        Aries     05,August,2004   \n",
       "4743  4013263  female   23   Automotive     Aquarius       23,July,2004   \n",
       "4280   766556  female   34       indUnk  Sagittarius    06,January,2003   \n",
       "4198   766556  female   34       indUnk  Sagittarius   22,November,2002   \n",
       "1176  1238294  female   33       indUnk          Leo       21,July,2004   \n",
       "4517   766556  female   34       indUnk  Sagittarius    01,October,2003   \n",
       "4155   766556  female   34       indUnk  Sagittarius  16,September,2002   \n",
       "3188   589736    male   35   Technology        Aries     05,August,2004   \n",
       "2885   589736    male   35   Technology        Aries     05,August,2004   \n",
       "680   3176655    male   24  Engineering        Libra       03,July,2004   \n",
       "3760  3887270  female   17      Student          Leo       21,July,2004   \n",
       "3756  3887270  female   17      Student          Leo       22,July,2004   \n",
       "4938  1103575  female   17       indUnk      Scorpio       28,July,2003   \n",
       "570   3808902  female   45       indUnk  Sagittarius       02,July,2004   \n",
       "2113   589736    male   35   Technology        Aries     05,August,2004   \n",
       "\n",
       "                                                   text  \n",
       "1602             Okay  a  how does one stumble upon ...  \n",
       "2771             Here in this place I have no sound ...  \n",
       "2358             did anyone besides me see our frien...  \n",
       "2947             yep and i have a copy on the way   ...  \n",
       "4743                   My new job is greatnbsp I sta...  \n",
       "4280          Another  Borrowed  Toy  My  Cyborg  na...  \n",
       "4198          Oh What a night  Late September back i...  \n",
       "1176               I finished another  urlLink tiny ...  \n",
       "4517          Oh and one more thing   October is her...  \n",
       "4155          Cleaning House   First of all thanks t...  \n",
       "3188             RTG  check your ehemail Sunday morn...  \n",
       "2885             right now i have on no shoes  no sh...  \n",
       "680                    Happy friday    I am happy an...  \n",
       "3760               oh YEAH and im the FIRST PERSON O...  \n",
       "3756             Some people live for the fortune  S...  \n",
       "4938         Sometimes    I think my name is Jane   ...  \n",
       "570          Well Independance Day is upon us and I ...  \n",
       "2113             Waiting for the Feeling Police   Al...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs['text'] = blogs['text'].apply(expand_contractions)  # applying expand_contractions function on the text column\n",
    "blogs['text'] = blogs['text'].apply(remove_spl_char_n_numbers) # applying remove_spl_char_n_numbers function on the text column\n",
    "blogs.sample(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blogs.drop(columns=[\"gender\", 'age','sign','date','text_new'],inplace=True)\n",
    "# blogs.drop(columns=['text_new2'],inplace=True)\n",
    "# blogs.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import unicodedata\n",
    "# def remove_accented_chars(text):\n",
    "#     text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "#     return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def simple_stemmer(text):\n",
    "#     ps = nltk.porter.PorterStemmer()\n",
    "#     text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "#     return text\n",
    "\n",
    "# simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")\n",
    "\n",
    "\n",
    "\n",
    "# def lemmatize_text(text):\n",
    "#     text = nlp(text)\n",
    "#     text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "#     return text\n",
    "\n",
    "# lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")\n",
    "\n",
    "\n",
    "# def remove_stopwords(text, is_lower_case=False):\n",
    "#     tokens = tokenizer.tokenize(text)\n",
    "#     tokens = [token.strip() for token in tokens]\n",
    "#     if is_lower_case:\n",
    "#         filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "#     else:\n",
    "#         filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "#     filtered_text = ' '.join(filtered_tokens)    \n",
    "#     return filtered_text\n",
    "\n",
    "# remove_stopwords(\"The, and, if are stopwords, computer is not\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B. Lowercase all textual data [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>766556</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>14,June,2004</td>\n",
       "      <td>depressed  my  urllink boyfriend  stil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>i appreciate your opinion re the is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>1415200</td>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>it is  in the morning and im up because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>i think we should just trust our pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  gender  age       topic         sign            date  \\\n",
       "4615   766556  female   34      indUnk  Sagittarius    14,June,2004   \n",
       "2492   589736    male   35  Technology        Aries  05,August,2004   \n",
       "1116  1415200  female   15     Student        Libra    10,June,2004   \n",
       "3003   589736    male   35  Technology        Aries  05,August,2004   \n",
       "\n",
       "                                                   text  \n",
       "4615          depressed  my  urllink boyfriend  stil...  \n",
       "2492             i appreciate your opinion re the is...  \n",
       "1116         it is  in the morning and im up because...  \n",
       "3003             i think we should just trust our pr...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs['text'] = blogs['text'].apply(lambda x:x.lower())    #LOWERCASE\n",
    "blogs.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        C. Remove all Stopwords [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,July,2004</td>\n",
       "      <td>must nuts every months take canada weeks lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>3644456</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>21,July,2004</td>\n",
       "      <td>hit dognbspaka former red sox b suv accident t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>fat nothin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>1103575</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>28,August,2003</td>\n",
       "      <td>sometimes swear song matchbox twenty say cold ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  gender  age              topic      sign            date  \\\n",
       "47    3581210    male   33  InvestmentBanking  Aquarius    11,July,2004   \n",
       "1015  3644456    male   23             indUnk    Taurus    21,July,2004   \n",
       "2334   589736    male   35         Technology     Aries  05,August,2004   \n",
       "4990  1103575  female   17             indUnk   Scorpio  28,August,2003   \n",
       "\n",
       "                                                   text  \n",
       "47    must nuts every months take canada weeks lates...  \n",
       "1015  hit dognbspaka former red sox b suv accident t...  \n",
       "2334                                         fat nothin  \n",
       "4990  sometimes swear song matchbox twenty say cold ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "blogs['text'] = blogs['text'].apply(remove_stopwords)  #STOP WORDS\n",
    "blogs.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "        D. Remove all extra white spaces [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>someone right explain iraq learned morning com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>larry muy linda better stop calling thehem wac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>3367100</td>\n",
       "      <td>male</td>\n",
       "      <td>39</td>\n",
       "      <td>Communications-Media</td>\n",
       "      <td>Libra</td>\n",
       "      <td>01,June,2004</td>\n",
       "      <td>exercise dehemocratic right get vote ok someon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>3176655</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Libra</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>sometimes brightest bulb chandelier trying hoo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id gender  age                 topic   sign            date  \\\n",
       "3294   589736   male   35            Technology  Aries  05,August,2004   \n",
       "3534   589736   male   35            Technology  Aries  05,August,2004   \n",
       "3706  3367100   male   39  Communications-Media  Libra    01,June,2004   \n",
       "673   3176655   male   24           Engineering  Libra    03,July,2004   \n",
       "\n",
       "                                                   text  \n",
       "3294  someone right explain iraq learned morning com...  \n",
       "3534  larry muy linda better stop calling thehem wac...  \n",
       "3706  exercise dehemocratic right get vote ok someon...  \n",
       "673   sometimes brightest bulb chandelier trying hoo...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_whitespaces(text):\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "blogs['text'] = blogs['text'].apply(remove_whitespaces)  #leading white spaces\n",
    "blogs.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a base Classification model [8 Marks]\n",
    "        A. Create dependent and independent variables [2 Marks]\n",
    "        Hint: Treat ‘topic’ as a Target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since X = blogs['text'] and y =blogs['topic']\n",
    "\n",
    "x = blogs['text']\n",
    "\n",
    "y = blogs['topic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B. Split data into train and test. [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train :  (3550,)\n",
      "Shape of x_test :  (1184,)\n",
      "Shape of y_train :  (3550,)\n",
      "Shape of y_test :  (1184,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test =train_test_split(x,y, random_state=369)\n",
    "\n",
    "print(\"Shape of x_train : \", x_train.shape)\n",
    "print(\"Shape of x_test : \", x_test.shape)\n",
    "print(\"Shape of y_train : \", y_train.shape)\n",
    "print(\"Shape of y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        C. Vectorize data using any one vectorizer. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (3550,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3445"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "cv = CountVectorizer(min_df=10) # lowercase=True,stop_words='english' are handled already\n",
    "print('x shape:',x_train.shape)\n",
    "cv.fit_transform(x_train)\n",
    "#Check the vocablury size\n",
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3550, 3445)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert Training blog text into Count Vectors\n",
    "x_train_ct = cv.transform(x_train)\n",
    "\n",
    "#Size of Document Term Matrix\n",
    "x_train_ct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1184, 3445)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply transform on test data\n",
    "x_test_ct = cv.transform(x_test)\n",
    "x_test_ct.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        D. Build a base model for Supervised Learning - Classification. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features :  3445\n",
      "Training Accuracy :  0.7997183098591549\n",
      "Testing Accuracy :  0.6537162162162162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_ct, y_train)\n",
    "y_pred_class = nb.predict(x_test_ct)\n",
    "print(\"Number of Features : \", x_train_ct.shape[1])\n",
    "print(\"Training Accuracy : \",nb.score(x_train_ct,y_train ))\n",
    "print(\"Testing Accuracy : \", nb.score(x_test_ct,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        E. Clearly print Performance Metrics. [1 Marks]\n",
    "        Hint: Accuracy, Precision, Recall, ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Accounting       0.00      0.00      0.00         1\n",
      "                Arts       0.00      0.00      0.00         6\n",
      "          Automotive       0.00      0.00      0.00         4\n",
      "             Banking       0.00      0.00      0.00         5\n",
      "    BusinessServices       0.00      0.00      0.00        20\n",
      "Communications-Media       0.50      0.12      0.20        16\n",
      "          Consulting       1.00      0.50      0.67         4\n",
      "           Education       0.42      0.38      0.40        29\n",
      "         Engineering       0.65      0.40      0.49        43\n",
      "            Internet       0.00      0.00      0.00         6\n",
      "   InvestmentBanking       0.83      0.79      0.81        19\n",
      "                 Law       0.00      0.00      0.00         1\n",
      "          Non-Profit       0.57      0.40      0.47        10\n",
      "             Science       1.00      0.33      0.50         9\n",
      "   Sports-Recreation       0.42      0.85      0.56        13\n",
      "             Student       0.54      0.59      0.57       149\n",
      "          Technology       0.85      0.70      0.77       530\n",
      "              indUnk       0.53      0.78      0.63       319\n",
      "\n",
      "            accuracy                           0.65      1184\n",
      "           macro avg       0.41      0.32      0.34      1184\n",
      "        weighted avg       0.67      0.65      0.64      1184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the confusion matrix\n",
    "# print(confusion_matrix(y_test, y_pred_class))\n",
    "# Printing the precision and recall, among other metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Improve Performance of model. [14 Marks]\n",
    "        A. Experiment with other vectorisers. [4 Marks]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3445"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets use Tfidf Vectorizer now\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(min_df=10)\n",
    "tv.fit_transform(x_train)\n",
    "#Check the vocablury size\n",
    "len(tv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3550, 3445)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert Training blog text into Count Vectors\n",
    "x_train_tv = tv.transform(x_train)\n",
    "\n",
    "#Size of Document Term Matrix\n",
    "x_train_tv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1184, 3445)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply transform on test data\n",
    "x_test_tv = tv.transform(x_test)\n",
    "x_test_tv.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B. Build classifier Models using other algorithms than base model. [4 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features :  3445\n",
      "Training Accuracy :  0.9845070422535211\n",
      "Testing Accuracy :  0.6216216216216216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(max_depth=100)\n",
    "rfclf.fit(x_train_tv, y_train)\n",
    "y_pred_class = nb.predict(x_test_ct)\n",
    "print(\"Number of Features : \", x_train_tv.shape[1])\n",
    "print(\"Training Accuracy : \",rfclf.score(x_train_tv,y_train))\n",
    "print(\"Testing Accuracy : \", rfclf.score(x_test_tv,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        C. Tune Parameters/Hyperparameters of the model/s. [4 Marks]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf2 = RandomForestClassifier(max_depth=200)\n",
    "rfclf2.fit(x_train_tv, y_train)\n",
    "y_pred_class = nb.predict(x_test_ct)\n",
    "print(\"Number of Features : \", x_train_tv.shape[1])\n",
    "print(\"Training Accuracy : \",rfclf2.score(x_train_tv,y_train ))\n",
    "print(\"Testing Accuracy : \", rfclf2.score(x_test_tv,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        D. Clearly print Performance Metrics. [2 Marks]\n",
    "            Hint: Accuracy, Precision, Recall, ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Share insights on relative performance comparison [8 Marks]\n",
    "        A. Which vectorizer performed better? Probable reason?.[2 Marks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B. Which model outperformed? Probable reason? [2 Marks]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        C. Which parameter/hyperparameter significantly helped to improve performance?Probable reason?. [2 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        D. According to you, which performance metric should be given most importance, why?. [2 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # PART B - 20 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • DOMAIN: \n",
    "    Customer support\n",
    "### • CONTEXT: \n",
    "    Great Learning has a an academic support department which receives numerous support requests every day throughout the year. Teams are spread across geographies and try to provide support round the year. Sometimes there are circumstances where due to heavy workload certain request resolutions are delayed, impacting company’s business. Some of the requests are very generic where a proper resolution procedure delivered to the user can solve the problem. Company is looking forward to design an automation which can interact with the user, understand the problem and display the resolution procedure [ if found as a generic request ] or redirect the request to an actual human support executive if the request is complex or not in it’s database.\n",
    "### • DATA DESCRIPTION: \n",
    "    A sample corpus is attached for your reference. Please enhance/add more data to the corpus using your linguistics skills.\n",
    "### • PROJECT OBJECTIVE: \n",
    "    Design a python based interactive semi - rule based chatbot which can do the following:\n",
    "        1. Start chat session with greetings and ask what the user is looking for. [5 Marks]\n",
    "        2. Accept dynamic text based questions from the user. Reply back with relevant answer from the designed corpus. [10 Marks]\n",
    "        3. End the chat session only if the user requests to end else ask what the user is looking for. Loop continues till the user asks to end it. [5 Marks]\n",
    "        Hint: There are a lot of techniques using which one can clean and prepare the data which can be used to train a ML/DL classifier. Hence, it might require you to experiment, research, self learn and implement the above classifier. There might be many iterations between hand building the corpus and designing the best fit text classifier. As the quality and quantity of corpus increases the model’s performance i.e. ability to answer\n",
    "        right questions also increases.\n",
    "        Reference: https://www.mygreatlearning.com/blog/basics-of-building-an-artificial-intelligence-chatbot/\n",
    "### • Evaluation: \n",
    "    Evaluator will use linguistics to twist and turn sentences to ask questions on the topics described in DATA DESCRIPTION and check if the bot is giving relevant replies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texttospeech' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18104/113463108.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtexttospeech\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'texttospeech' is not defined"
     ]
    }
   ],
   "source": [
    "texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "text = pyttsx3.init()\n",
    "s = 'The code is Compiled'\n",
    "text.say(s)\n",
    "text.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
